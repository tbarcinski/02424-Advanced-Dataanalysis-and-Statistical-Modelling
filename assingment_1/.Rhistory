-dnorm(x.ave, mean = theta, sd = sqrt(s2/n))
}
th <- seq(x.ave - 3 * sqrt(s2), x.ave + 3 * sqrt(s2), length = 200)
L <- sapply(th, L.complete.data)
plot(th, log(L/max(L)), ylab = "L", xlab = expression(theta))
L <- sapply(th, L.ave)
lines(th, log(L/max(L)), col = "red")
th <- seq(x.ave - 3 * sqrt(s2), x.ave + 3 * sqrt(s2), length = 200)
L <- sapply(th, L.complete.data)
plot(th, log(L) - log(max(L)), ylab = "L", xlab = expression(theta))
L <- sapply(th, L.ave)
lines(th, log(L) - log(max(L)), col = "red")
L.ave <- function(theta) {
dnorm(x.ave, mean = theta, sd = sqrt(s2/n))
}
th <- seq(x.ave - 3 * sqrt(s2), x.ave + 3 * sqrt(s2), length = 200)
L <- sapply(th, L.complete.data)
plot(th, log(L/max(L)), ylab = "L", xlab = expression(theta))
L <- sapply(th, L.ave)
lines(th, log(L/max(L)), col = "red")
th <- seq(x.ave - 3 * sqrt(s2), x.ave + 3 * sqrt(s2), length = 200)
L <- sapply(th, L.complete.data)
plot(th, log(L) - log(max(L)), ylab = "L", xlab = expression(theta))
L <- sapply(th, L.ave)
lines(th, log(L) - log(max(L)), col = "red")
th <- seq(x.ave - 3 * sqrt(s2), x.ave + 3 * sqrt(s2), length = 200)
L <- sapply(th, L.complete.data)
plot(th, -log(L) + log(max(L)), ylab = "L", xlab = expression(theta))
L <- sapply(th, L.ave)
lines(th, -log(L) + log(max(L)), col = "red")
x <- c(71, 74, 82, 76, 91, 82, 82, 75, 79, 82, 72, 90)
s2 <- var(x)
L.complete.data <- function(theta) {
prod(dnorm(x, mean = theta, sd = sqrt(s2)))
}
x.ave <- mean(x)
n <- length(x)
L.ave <- function(theta) {
dnorm(x.ave, mean = theta, sd = sqrt(s2/n))
}
th <- seq(x.ave - 3 * sqrt(s2), x.ave + 3 * sqrt(s2), length = 200)
L <- sapply(th, L.complete.data)
plot(th, log(L/max(L)), ylab = "L", xlab = expression(theta))
L <- sapply(th, L.ave)
lines(th, log(L/max(L)), col = "red")
x.ave
?optim
nll.complete.data <- function(theta) {
-sum(dnorm(x, mean = theta, sd = sqrt(s2), log = TRUE))
}
fit <- optim(x.ave, nll.complete.data, hessian = TRUE,
lower=70, upper=90)
fit[c("convergence", "par", "hessian")]
s2
var(x)
sd(x)
x <- c(4,6,3,7,2,4)
lambda_vector <- seq(0, 10, length.out = 100)
likelihood <- function(lambda){
prod(dpois(x, lambda = lambda))
}
likelihood_plotting <- sapply(lambda_vector, likelihood)
plot(lambda_vector, likelihood_plotting, type = "l")
par(mar=c(1,1,1,1))
plot(lambda_vector, likelihood_plotting, type = "l")
device.off()
x <- c(71, 74, 82, 76, 91, 82, 82, 75, 79, 82, 72, 90)
s2 <- var(x)
L.complete.data <- function(theta) {
prod(dnorm(x, mean = theta, sd = sqrt(s2)))
}
x.ave <- mean(x)
n <- length(x)
L.ave <- function(theta) {
dnorm(x.ave, mean = theta, sd = sqrt(s2/n))
}
th <- seq(x.ave - 3 * sqrt(s2), x.ave + 3 * sqrt(s2), length = 200)
L <- sapply(th, L.complete.data)
plot(th, log(L/max(L)), ylab = "L", xlab = expression(theta))
L <- sapply(th, L.ave)
lines(th, log(L/max(L)), col = "red")
###### UNDERSTANDING INVERSE COVARIANCE ################
library(mvtnorm)
?dmvnorm
x <- 5
x <- 5
rm(list=ls())
print(utils::getSrcDirectory(function(){}))
print(utils::getSrcFilename(function(){}, full.names = TRUE))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# options(scipen=999)
options(scipen=0)
# dev.off()
library(MASS)
library(dplyr)
# library(tsibble)
library(forecast)
# library(matlib)
library(nlme)
n_3 = 300
simulations_number_3 = 100
phi_2_list = c(-0.52, -0.98)
sigma_squared_list = c(0.1^2, 5^2)
parameters_3 = c("phi_1" = 1.5, "phi_2" = NA)
results_3 <- array(NA, dim=c(4, n_3, simulations_number_3))
# dim(results_3): (4, 300, 100)
# simulations
index = 1
for(phi_2 in phi_2_list){
for(sigma_2 in sigma_squared_list){
results_tmp = matrix(NA, nrow = n_3, ncol = simulations_number_3)
for (i in 1:simulations_number_3){
results_tmp[,i] = arima.sim(n = n_3,
list(ar = c(parameters_3[1], phi_2),
sd = sigma_2))
}
results_3[index, , ] = as.array(results_tmp)
index = index + 1
}
}
estimation_phi_2 <- array(NA, dim=c(4, simulations_number_3))
estimation_full <- array(NA, dim=c(4, 2, simulations_number_3))
# estimation of phi_2
for(i in 1:dim(results_3)[1]){
for(j in 1:dim(results_3)[3]){
series = results_3[i, ,j]
model_tmp = arima(series, order = c(2, 0, 0),
include.mean = FALSE,
fixed = parameters_3)
estimation_phi_2[i, j] = model_tmp$coef["ar2"]
model_tmp_full <- arima(series, order = c(2, 0, 0),
include.mean = FALSE)
estimation_full[i, ,j] =  model_tmp_full$coef[c("ar1", "ar2")]
}
}
n_bins = 20
par(mfrow=c(2,2))
hist(t(estimation_phi_2)[, 1], breaks = n_bins)
hist(t(estimation_phi_2)[, 2], breaks = n_bins)
hist(t(estimation_phi_2)[, 3], breaks = n_bins)
hist(t(estimation_phi_2)[, 4], breaks = n_bins)
par(mfrow=c(2,2))
plot(estimation_full[1, 1, ], estimation_full[1, 2, ])
plot(estimation_full[2, 1, ], estimation_full[2, 2, ])
plot(estimation_full[3, 1, ], estimation_full[3, 2, ])
plot(estimation_full[4, 1, ], estimation_full[4, 2, ])
df <- read.table("A2_sales.txt", sep="",header=TRUE)
df <- df %>%
mutate(year = as.numeric(substr(Quarter, 1, 4)),
quarter = as.numeric(substr(Quarter, 6, 6)),
index = seq(1, dim(df)[1])) %>%
mutate(time = as.numeric(year + (quarter - 1)/4))
mu = 2070
period = 4
noise_variance = 36963
par(mfrow=c(1,1))
plot(df$index, df$Sales - mu)
parameters_2 = c("phi_1" = 1.04, "phi_2" = 0.2, "Phi_1" = 0.86,
"Theta_1" = -0.42, "mu" = mu)
model <- arima(df$Sales, order = c(2, 0, 0),
seasonal = list(order = c(1, 0, 1), period = period),
include.mean = TRUE,
fixed = parameters_2)
str(model)
predictions <- predict(model, n.ahead = 2, se.fit = TRUE)
predictions
summary(model)
model$sigma2
model_our_sigma <- model
str(model_our_sigma)$sigma2 <- noise_variance
model_our_sigma$sigma2 <- noise_variance
str(model_our_sigma)
predictions_our_sigma <- predict(model_our_sigma, n.ahead = 2, se.fit = TRUE)
predictions_our_sigma
predictions
n = 200
parameters_1 = c("phi_1" = 0.8, "theta_1" = 0.8, "theta_2" = -0.5, "std_noise" = 0.4)
simulations_number = 10
results = matrix(NA, nrow = n, ncol = simulations_number)
for (i in 1:simulations_number){
results[,i] = arima.sim(n = n, list(ar = parameters_1[1], ma = parameters_1[2:3]),
sd = parameters_1[4])
}
dim(results)
average_model <- apply(results, MARGIN = 1, mean)
acf_plot <- acf(average_model)
plot(acf_plot)
MAX_LAG = 20
par(mfrow=c(1,1))
matplot(results, type = "l", col = "grey")
lines(average_model, col = "red", lwd = 2)
acf_full <- acf(results, na.action=na.pass, plot=FALSE, lag.max = MAX_LAG)
n_3 = 300
simulations_number_3 = 100
phi_2_list = c(-0.52, -0.98)
sigma_squared_list = c(0.1^2, 5^2)
parameters_3 = c("phi_1" = 1.5, "phi_2" = NA)
results_3 <- array(NA, dim=c(4, n_3, simulations_number_3))
n_3 = 300
simulations_number_3 = 100
phi_2_list = c(-0.52, -0.98)
sigma_squared_list = c(0.1^2, 5^2)
parameters_3 = c("phi_1" = 1.5, "phi_2" = NA)
results_3 <- array(NA, dim=c(length(phi_2_list), length(sigma_squared_list),
n_3, simulations_number_3))
# dim(results_3): (2, 2, 300, 100)
# phi, sigma, n_3, simulations_number_3
# simulations
for(i in 1:length(phi_2_list)){
for(j in 1:length(phi_2_list)){
results_tmp = matrix(NA, nrow = n_3, ncol = simulations_number_3)
phi_2 = phi_2_list[i]
sigma_2 = sigma_squared_list[j]
for (index in 1:simulations_number_3){
results_tmp[,index] = arima.sim(n = n_3,
list(ar = c(parameters_3[1], phi_2),
sd = sigma_2))
}
results_3[i, j, , ] = as.array(results_tmp)
}
}
dim(results_3)
# estimation_phi_2 <- array(NA, dim=c(4, simulations_number_3))
estimation_full <- array(NA, dim=c(2, 2, 2, simulations_number_3))
# phi, sigma, n_3, estimation_parameters, simulations_number_3
for(i in 1:length(phi_2_list)){
for(j in 1:length(phi_2_list)){
for(simulation_number in 1:simulations_number_3){
series = results_3[i,j, ,simulations_number]
model_tmp_full <- arima(series, order = c(2, 0, 0),
include.mean = FALSE)
estimation_full[i,j, ,simulation_number] =  model_tmp_full$coef[c("ar1", "ar2")]
}
}
}
estimation_full
rm(list=ls())
print(utils::getSrcDirectory(function(){}))
print(utils::getSrcFilename(function(){}, full.names = TRUE))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
Sys.setenv(LANG = "en")
library(MASS)
library(dplyr)
library(nortest)
library(GGally)
library(ggplot2)
library(corrplot)
library(tree)
library(car)
library(patchwork)
library(mvtnorm)
library(nlme)
library(numDeriv)
library(fitdistrplus)
library(lmtest)
library(leaps)
library(plotly)
# Reading data
dat <- read.table("dioxin.csv", sep=',', head=TRUE)
df <- data.frame(dat)
df <- df %>% select(-OBSERV)
summary(df)
is.na(df)
colSums(is.na(df))
# PRSEK, CO, SO2
sum(is.na(df))
table(df$PRSEK, useNA ="ifany")  # Observation 15 and 16 are missing
tapply(df$QRAT, df$PRSEK, mean, useNA="ifany")  # Observations seems to have been "L"
df$PRSEK[15:16] <- "L"
model_1 <- lm(DIOX ~ OXYGEN + LOAD + PRSEK + PLANT + TIME + LAB)
attach(df)
model_1 <- lm(DIOX ~ OXYGEN + LOAD + PRSEK + PLANT + TIME + LAB)
summary(model_1)
par(mfrow = c(2, 2))
plot(model_1, which = 1:4)
stdresid <- rstandard(model_1)
par(mfrow=c(2, 2))
plot(model_1, which = 1)
plot(model_1, which = 3)
hist(stdresid, main="", probability=TRUE, breaks=10)
curve(dnorm, -3, 3, col="red", lwd=2, add=TRUE)
plot(model_1, which=2)
par(mfrow=c(1, 1))
model_1_log <- lm(log(DIOX) ~ OXYGEN + LOAD + PRSEK + PLANT + TIME + LAB, data = df)
summary(model_1_log)
stdresid <- rstandard(model_1_log)
par(mfrow=c(2, 2))
plot(model_1_log, which = 1)
plot(model_1_log, which = 3)
hist(stdresid, main="", probability=TRUE, breaks=10)
curve(dnorm, -3, 3, col="red", lwd=2, add=TRUE)
plot(model_1_log, which=2)
rm(list=ls())
print(utils::getSrcDirectory(function(){}))
print(utils::getSrcFilename(function(){}, full.names = TRUE))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
Sys.setenv(LANG = "en")
library(MASS)
library(dplyr)
library(nortest)
library(GGally)
library(ggplot2)
library(corrplot)
library(tree)
library(car)
library(patchwork)
library(mvtnorm)
library(nlme)
library(numDeriv)
library(fitdistrplus)
library(lmtest)
library(leaps)
library(plotly)
dat <- read.table("dioxin.csv", sep=',', head=TRUE)
df <- data.frame(dat)
df <- df %>% select(-OBSERV)
summary(df)
is.na(df)
colSums(is.na(df))
# PRSEK, CO, SO2
sum(is.na(df))
AM3 <- lm(log(DIOX) ~ O2COR + PLANT + TIME + LAB + CO2 + TROEG + POVN +
poly(log(HCL), 2) + TIME:poly(NEFFEKT, 1), data = df)
summary(AM3)
AM3 <- lm(log(DIOX) ~ O2COR + PLANT + NEFFEKT + TIME + LAB + CO2 + TROEG + POVN +
poly(log(HCL), 2) + TIME:poly(NEFFEKT, 1), data = data.frame(df))
summary(AM3)
dat <- read.table("dioxin.csv", sep=',', head=TRUE)
df <- data.frame(dat)
df <- df %>% select(-OBSERV)
summary(df)
is.na(df)
colSums(is.na(df))
# PRSEK, CO, SO2
sum(is.na(df))
cols <- c("PLANT", "TIME", "LAB", "OXYGEN", "LOAD", "PRSEK")
df[cols] <- lapply(df[cols], as.factor)
df <- data.frame(df)
str(df)
attach(df)
AM3 <- lm(log(DIOX) ~ O2COR + PLANT + TIME + LAB + CO2 + TROEG + POVN +
poly(log(HCL), 2) + TIME:poly(NEFFEKT, 1), data = data.frame(df))
summary(AM3)
summary(AM3)
confint(AM3)
AM3 <- lm(log(DIOX) ~ O2COR + PLANT + TIME + LAB + CO2 + TROEG + POVN +
poly(log(HCL), 2) + TIME:poly(NEFFEKT, 1), data = data.frame(df))
summary(AM3)
c(AIC(AM3), BIC(AM3))
model_optimization <- AM3
design_matrix = model.matrix(model_optimization)
n = dim(design_matrix)[1]
p = dim(design_matrix)[2]
y = log(df$DIOX)
objective = function(theta){
y_hat = design_matrix %*% theta[1:p]
Sigma_weighted = diag(n)
diag(Sigma_weighted)[design_matrix[, "LABUSA"] == 0] = 1/theta[p+2]
# print(diag(Sigma_weighted))
# diag(Sigma_weighted)[design_matrix[, "LABUSA"] == 1] = (1 - theta[p+2])
Sigma_weighted = theta[p+1]*Sigma_weighted
result = sum(dmvnorm(y, mean = y_hat, sigma = Sigma_weighted, log = TRUE))
return(-result)
}
theat_initial = c(rep(1, length(model_optimization$coefficients)), "sigma_squared" = 1,
"weight" = 1)
opt <- nlminb(theat_initial, objective)
opt$par
hessian_matrix = hessian(objective,opt$par)
standard_error = sqrt(diag(solve(hessian_matrix)))
c(opt$par["weight"] - qnorm(0.975)*standard_error[length(standard_error)],
opt$par["weight"] + qnorm(0.975)*standard_error[length(standard_error)])
### look into likelihood based CI for weight parameter
## LRT between model with one sigma and model with 2 sigmas
### PROFILE LIKELIHOOD CI
profile_objective <- function(weight){
fun.tmp <- function(theta_inner, weight_input){
objective(c(theta_inner, weight_input))
}
theat_initial_inner_opt = c(rep(1, length(model_optimization$coefficients)),
"sigma_squared" = 1)
nlminb(theat_initial_inner_opt, fun.tmp, weight_input = weight)$objective
}
profile_objective(10)
p1 <- seq(-0.5, opt$par["weight"]*2.7, by = 0.05)
logLp1 <- sapply(p1, profile_objective) ## note sapply!
logLp1 <- logLp1 - min(logLp1) ## normalization
L_CI_lower = min(p1[exp(-logLp1) > exp(-qchisq(0.95,df=1)/2)])
L_CI_upper =  max(p1[exp(-logLp1) > exp(-qchisq(0.95,df=1)/2)])
obs_hessian <- hessian(profile_objective, opt$par["weight"])[1, 1]
quadratic_approximation <-
exp( -0.5* obs_hessian * (p1 - opt$par["weight"])^2)
quadratic_approximation <- quadratic_approximation / max(quadratic_approximation)
par(mfrow = c(1,1))
plot(p1, exp(-logLp1), type = "l",
xlab="Weight", ylab="Profile Likelihood",
main="The comparison between Wald's and Likelihood based Confidence Intervals")
par(mfrow = c(1,1))
plot(p1, exp(-logLp1), type = "l",
xlab="Weight", ylab="Profile Likelihood",
main="The comparison between Wald's and Likelihood based Confidence Intervals")
axis(side=1, at=seq(0, 10, by=1))
lines(p1, rep(exp(-qchisq(0.95,df=1)/2), length(p1)), col = 2)
rug(L_CI_lower, ticksize = 0.1, lwd = 2, col = "red")
rug(L_CI_upper, ticksize = 0.1, lwd = 2, col = "red")
c(L_CI_lower, L_CI_upper)
lines(p1, quadratic_approximation, col = "blue")
abline(v = opt$par["weight"], lty = 2)
rug(opt$par["weight"] - qnorm(0.975)*standard_error[length(standard_error)],
ticksize = 0.1, lwd = 2, col = "blue")
rug(opt$par["weight"] + qnorm(0.975)*standard_error[length(standard_error)],
ticksize = 0.1, lwd = 2, col = "blue")
legend("topright", 95,
legend=c("Profile likelihood", "Quadratic approximation",
"95% confidence interval"),
col=c("black", "blue", "red"), lty = 1:1, cex=0.8,
inset = 0.02)
c(opt$par["weight"] - qnorm(0.975)*standard_error[length(standard_error)],
opt$par["weight"] + qnorm(0.975)*standard_error[length(standard_error)])
c(L_CI_lower, L_CI_upper)
p1 <- seq(-0.5, opt$par["weight"]*2.7, by = 0.01)
logLp1 <- sapply(p1, profile_objective) ## note sapply!
logLp1 <- logLp1 - min(logLp1) ## normalization
L_CI_lower = min(p1[exp(-logLp1) > exp(-qchisq(0.95,df=1)/2)])
L_CI_upper =  max(p1[exp(-logLp1) > exp(-qchisq(0.95,df=1)/2)])
obs_hessian <- hessian(profile_objective, opt$par["weight"])[1, 1]
quadratic_approximation <-
exp( -0.5* obs_hessian * (p1 - opt$par["weight"])^2)
quadratic_approximation <- quadratic_approximation / max(quadratic_approximation)
c(opt$par["weight"] - qnorm(0.975)*standard_error[length(standard_error)],
opt$par["weight"] + qnorm(0.975)*standard_error[length(standard_error)])
c(L_CI_lower, L_CI_upper)
p1
standard_error[length(standard_error)]
profile_final_model^2
wald_statistic = (opt$par["weight"] - 1)/standard_error[length(standard_error)]
wald_statistic
ll_full <- -profile_objective(as.numeric(opt$par["weight"]))
ll_test <- -profile_objective(1)
LRT <- -2*(ll_test - (ll_full))
p <- 1 - pchisq(LRT, df = 1)
p
dat <- read.table("dioxin.csv", sep=',', head=TRUE)
df <- data.frame(dat)
df <- df %>% select(-OBSERV)
summary(df)
is.na(df)
colSums(is.na(df))
# PRSEK, CO, SO2
sum(is.na(df))
cols <- c("PLANT", "TIME", "LAB", "OXYGEN", "LOAD", "PRSEK")
df[cols] <- lapply(df[cols], as.factor)
df <- data.frame(df)
model_interactions <- lm(log(DIOX) ~ O2COR + PLANT + TIME + LAB + CO2 + TROEG + POVN +
poly(log(HCL), 2) + TIME:poly(NEFFEKT, 1) + O2COR*NEFFEKT*QRAT, data = df)
summary(model_interactions)
drop(model_interactions, test = "F")
drop1(model_interactions, test = "F")
summary(model_interactions)
AM3 <- lm(log(DIOX) ~ O2COR  + NEFFEKT + PLANT + TIME + LAB, data = df)
scope <- ~ . + QROEG + TOVN + TROEG + POVN + CO2 + CO + SO2 + HCL + H2O +       # Passive variables
poly(O2COR,2) + poly(NEFFEKT,2) +  poly(QRAT,1) + poly(QRAT,2) +              # Active variables higher order terms
PLANT:poly(O2COR,1)   + PLANT:poly(O2COR,2) +                                 # PLANT interactions
PLANT:poly(NEFFEKT,1) + PLANT:poly(NEFFEKT,2) +
PLANT:poly(QRAT,1)    + PLANT:poly(QRAT,2) +
LAB:poly(O2COR,1)     + PLANT:poly(O2COR,2) +                                 # LAB interactions
LAB:poly(NEFFEKT,1)   + PLANT:poly(NEFFEKT,2) +
LAB:poly(QRAT,1)      + PLANT:poly(QRAT,2) +
TIME:poly(O2COR,1)    + TIME:poly(O2COR,2) +                                  # TIME interactions
TIME:poly(NEFFEKT,1)  + TIME:poly(NEFFEKT,2) +
TIME:poly(QRAT,1)     + TIME:poly(QRAT,2) +
poly(log(HCL),1) +  poly(log(HCL),2) +                                        # Higher order effects of log(HCL) and log(CO)
PLANT:poly(log(HCL),1) +  PLANT:poly(log(HCL),2) +
LAB:poly(log(HCL),1) +  LAB:poly(log(HCL),2) +
TIME:poly(log(HCL),1) +  TIME:poly(log(HCL),2) +
poly(log(CO),1) +  poly(log(CO),2) +
PLANT:poly(log(CO),1) +  PLANT:poly(log(CO),2) +
LAB:poly(log(CO),1) +  LAB:poly(log(CO),2) +
TIME:poly(log(CO),1) +  TIME:poly(log(CO),2)  +
(O2COR*NEFFEKT*QRAT)^2
fig <- plot_ly(df, x = ~O2COR, y = ~NEFFEKT, z = ~QRAT,
marker = list(color = ~log(DIOX), colorscale = c('#FFE1A1', '#683531'), showscale = TRUE))
fig <- fig %>% add_markers()
fig <- fig %>% layout(scene = list(xaxis = list(title = 'O2COR'),
yaxis = list(title = 'NEFFEKT'),
zaxis = list(title = 'QRAT')),
annotations = list(
x = 1.13,
y = 1.05,
text = 'log(DIOX)',
xref = 'paper',
yref = 'paper',
showarrow = FALSE
))
fig
fig <- plot_ly(df, x = ~O2COR, y = ~NEFFEKT, z = ~QRAT,
marker = list(color = ~(DIOX), colorscale = c('#FFE1A1', '#683531'), showscale = TRUE))
fig <- fig %>% add_markers()
fig <- fig %>% layout(scene = list(xaxis = list(title = 'O2COR'),
yaxis = list(title = 'NEFFEKT'),
zaxis = list(title = 'QRAT')),
annotations = list(
x = 1.13,
y = 1.05,
text = 'log(DIOX)',
xref = 'paper',
yref = 'paper',
showarrow = FALSE
))
fig
